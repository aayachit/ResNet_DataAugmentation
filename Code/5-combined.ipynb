{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"5_DL_Assign3.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"RaNOqfmLaNWD","colab_type":"code","colab":{}},"source":["%matplotlib inline\n","import matplotlib.pyplot as plt\n","\n","from __future__ import print_function\n","import numpy as np\n","\n","import keras\n","from keras.datasets import cifar10\n","from keras.layers import AveragePooling2D, Input, Flatten\n","from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n","from keras.callbacks import ReduceLROnPlateau\n","from keras.regularizers import l2\n","from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n","from keras.optimizers import Adam\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras import backend as K\n","from keras.models import Model\n","import os\n","\n","from sklearn.model_selection import train_test_split"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eKJv_FS4ChF-","colab_type":"text"},"source":["Mixup Augmentation"]},{"cell_type":"code","metadata":{"id":"VTVlrTzbQwMj","colab_type":"code","colab":{}},"source":["class MixupAugmentation():\n","    def __init__(self, X_train, y_train, batch_size=32, alpha=0.4, shuffle=True, datagen=None):\n","        self.X_train = X_train\n","        self.y_train = y_train\n","        self.batch_size = batch_size\n","        self.alpha = alpha\n","        self.shuffle = shuffle\n","        self.sample_num = len(X_train)\n","        self.datagen = datagen\n","\n","    def __call__(self):\n","        while True:\n","            indexes = self.__get_exploration_order()\n","            itr_num = int(len(indexes) // (self.batch_size * 2))\n","\n","            for i in range(itr_num):\n","                batch_ids = indexes[i * self.batch_size * 2:(i + 1) * self.batch_size * 2]\n","                X, y = self.__data_generation(batch_ids)\n","\n","                yield X, y\n","\n","    def __get_exploration_order(self):\n","        indexes = np.arange(self.sample_num)\n","\n","        if self.shuffle:\n","            np.random.shuffle(indexes)\n","\n","        return indexes\n","\n","    def __data_generation(self, batch_ids):\n","        _, h, w, c = self.X_train.shape\n","        l = np.random.beta(self.alpha, self.alpha, self.batch_size)\n","        X_l = l.reshape(self.batch_size, 1, 1, 1)\n","        y_l = l.reshape(self.batch_size, 1)\n","\n","        X1 = self.X_train[batch_ids[:self.batch_size]]\n","        X2 = self.X_train[batch_ids[self.batch_size:]]\n","        X = X1 * X_l + X2 * (1 - X_l)\n","\n","        if self.datagen:\n","            for i in range(self.batch_size):\n","                X[i] = self.datagen.random_transform(X[i])\n","                X[i] = self.datagen.standardize(X[i])\n","                \n","        if isinstance(self.y_train, list):\n","            y = []\n","\n","            for y_train_ in self.y_train:\n","                y1 = y_train_[batch_ids[:self.batch_size]]\n","                y2 = y_train_[batch_ids[self.batch_size:]]\n","                y.append(y1 * y_l + y2 * (1 - y_l))\n","        else:\n","            y1 = self.y_train[batch_ids[:self.batch_size]]\n","            y2 = self.y_train[batch_ids[self.batch_size:]]\n","            y = y1 * y_l + y2 * (1 - y_l)\n","\n","        return X, y"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ooSGtbeWHbhB","colab_type":"text"},"source":["Cutout Augmentation"]},{"cell_type":"code","metadata":{"id":"C0DCj5axHbUN","colab_type":"code","colab":{}},"source":["def random_cutout(p=0.5, v_l=0, v_h=255):\n","    def eraser(input_img):\n","        img_h, img_w, img_c = input_img.shape\n","        p_1 = np.random.rand()\n","\n","        if p_1 > p:\n","            return input_img\n","        \n","        w = 8\n","        mid_x = np.random.randint(0, img_w)\n","        mid_y = np.random.randint(0, img_h)\n","        \n","        c = np.random.uniform(v_l, v_h)\n","        input_img[mid_x - w : mid_x + w, mid_y - w : mid_y + w, :] = c\n","\n","        return input_img\n","\n","    return eraser"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Gcn-6xG_DOlu","colab_type":"text"},"source":["Standard Augmentation"]},{"cell_type":"code","metadata":{"id":"0rfO647_c1mZ","colab_type":"code","colab":{}},"source":["%matplotlib inline\n","import matplotlib.pyplot as plt\n","\n","def transform(new_img, shift, dirctn):\n","    assert dirctn in ['right', 'left', 'down', 'up'], 'dirctns should be top|up|left|right'\n","    img = new_img.copy()\n","    \n","    if dirctn == 'right':\n","        right_slice = img[:,:shift].shape\n","        img[:, shift:] = img[:, :-shift]\n","        img[:,:shift] = np.zeros(right_slice)\n","            \n","    if dirctn == 'left':\n","        left_slice = img[:, -shift:].shape\n","        img[:, :-shift] = img[:, shift:]\n","        img[:, -shift:] = np.zeros(left_slice)\n","    if dirctn == 'down':\n","        down_slice = img[:shift, :].shape\n","        img[shift:, :] = img[:-shift,:]\n","        img[:shift, :] = np.zeros(down_slice)\n","    if dirctn == 'up':\n","        upper_slice = img[-shift:,:].shape\n","        img[:-shift, :] = img[shift:, :]\n","        img[-shift:,:] = np.zeros(upper_slice)\n","    \n","    return img\n","\n","\n","def std_aug():\n","  def augment(image_in, p=0.5):\n","    K = 4\n","    k1 = np.random.randint(-K, K)\n","    k2 = np.random.randint(-K, K)\n","    \n","    #img_h, img_w, img_c = image_in.shape\n","    p_1 = np.random.rand()\n","    if k1!=0 and k2!=0:\n","      if k1>0:\n","        image_in = transform(image_in, shift=abs(k1), dirctn='up')\n","      else:\n","        image_in = transform(image_in, shift=abs(k1), dirctn='down')\n","\n","      if k2>0:\n","        image_in = transform(image_in, shift=abs(k2), dirctn='right')\n","      else:\n","        image_in = transform(image_in, shift=abs(k2), dirctn='left')\n","\n","    if p_1 > p:\n","      image_in = np.fliplr(image_in)\n","    return image_in\n","  return augment\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nb2PyFsBGCmU","colab_type":"text"},"source":["RESNET20"]},{"cell_type":"code","metadata":{"id":"vVbjtvRtnF_a","colab_type":"code","colab":{}},"source":["\n","def resnet_layer(inputs,\n","                 num_filters=16,\n","                 kernel_size=3,\n","                 strides=1,\n","                 activation='relu',\n","                 batch_normalization=True,\n","                 conv_first=True):\n","    conv = Conv2D(num_filters,\n","                  kernel_size=kernel_size,\n","                  strides=strides,\n","                  padding='same',\n","                  kernel_initializer='he_normal',\n","                  kernel_regularizer=l2(1e-4))\n","\n"," \n","\n","    x = inputs\n","    if conv_first:\n","        x = conv(x)\n","        if batch_normalization:\n","            x = BatchNormalization()(x)\n","        if activation is not None:\n","            x = Activation(activation)(x)\n","    else:\n","        if batch_normalization:\n","            x = BatchNormalization()(x)\n","        if activation is not None:\n","            x = Activation(activation)(x)\n","        x = conv(x)\n","    return x\n","\n","\n","def resnet_v2(input_shape, depth, num_classes=10):\n","    \n","    if (depth - 2) % 9 != 0:\n","        raise ValueError('depth should be 9n+2 (eg 56 or 110 in [b])')\n","    # Start model definition.\n","    num_filters_in = 16\n","    num_res_blocks = int((depth - 2) / 9)\n","\n","    inputs = Input(shape=input_shape)\n","    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths\n","    x = resnet_layer(inputs=inputs,\n","                     num_filters=num_filters_in,\n","                     conv_first=True)\n","\n","    # Instantiate the stack of residual units\n","    for stage in range(3):\n","        for res_block in range(num_res_blocks):\n","            activation = 'relu'\n","            batch_normalization = True\n","            strides = 1\n","            if stage == 0:\n","                num_filters_out = num_filters_in * 4\n","                if res_block == 0:  # first layer and first stage\n","                    activation = None\n","                    batch_normalization = False\n","            else:\n","                num_filters_out = num_filters_in * 2\n","                if res_block == 0:  # first layer but not first stage\n","                    strides = 2    # downsample\n","\n","            # bottleneck residual unit\n","            y = resnet_layer(inputs=x,\n","                             num_filters=num_filters_in,\n","                             kernel_size=1,\n","                             strides=strides,\n","                             activation=activation,\n","                             batch_normalization=batch_normalization,\n","                             conv_first=False)\n","            y = resnet_layer(inputs=y,\n","                             num_filters=num_filters_in,\n","                             conv_first=False)\n","            y = resnet_layer(inputs=y,\n","                             num_filters=num_filters_out,\n","                             kernel_size=1,\n","                             conv_first=False)\n","            if res_block == 0:\n","                # linear projection residual shortcut connection to match\n","                # changed dims\n","                x = resnet_layer(inputs=x,\n","                                 num_filters=num_filters_out,\n","                                 kernel_size=1,\n","                                 strides=strides,\n","                                 activation=None,\n","                                 batch_normalization=False)\n","            x = keras.layers.add([x, y])\n","\n","        num_filters_in = num_filters_out\n","\n","    # Add classifier on top.\n","    # v2 has BN-ReLU before Pooling\n","    x = BatchNormalization()(x)\n","    x = Activation('relu')(x)\n","    x = AveragePooling2D(pool_size=8)(x)\n","    y = Flatten()(x)\n","    outputs = Dense(num_classes,\n","                    activation='softmax',\n","                    kernel_initializer='he_normal')(y)\n","\n","    # Instantiate model.\n","    model = Model(inputs=inputs, outputs=outputs)\n","    return model\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Y7fNOP8ZGcCJ","colab_type":"text"},"source":["Data Preparation"]},{"cell_type":"code","metadata":{"id":"Du7hh1Gx-AUk","colab_type":"code","colab":{}},"source":["\n","(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","\n","input_shape = x_train.shape[1:]\n","\n","x_train = x_train.astype('float32') / 255\n","x_test = x_test.astype('float32') / 255\n","\n","x_train, X_test, y_train, Y_test = train_test_split(x_train, y_train, stratify=y_train, test_size=0.8)\n","\n","N = 10\n","\n","y_train = keras.utils.to_categorical(y_train, N)\n","y_test = keras.utils.to_categorical(y_test, N)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0bs8Rxo2GfIO","colab_type":"text"},"source":["Training Parameters"]},{"cell_type":"code","metadata":{"id":"viBOS5ud99UB","colab_type":"code","colab":{}},"source":["batch_size = 128 \n","epochs = 100\n","#N = 10\n","\n","n=3\n","depth = n*6+2\n","model_type = 'ResNet%dv' % (depth)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zqZULwWSGjRg","colab_type":"text"},"source":["Model"]},{"cell_type":"code","metadata":{"id":"iFXODoGRrSbN","colab_type":"code","outputId":"3aaeec7f-9603-4641-b725-80196890a673","executionInfo":{"status":"ok","timestamp":1590921863581,"user_tz":420,"elapsed":2142005,"user":{"displayName":"Abhishek Ayachit","photoUrl":"","userId":"12945758249956481508"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["model = resnet_v2(input_shape=input_shape, depth=depth)\n","\n","\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=Adam(learning_rate=0.001),\n","              metrics=['accuracy'])\n","\n","#Standard Augmentation\n","datagen = ImageDataGenerator(\n","        preprocessing_function=std_aug())\n","\n","datagen.fit(x_train)\n","\n","#Cutout Augmentation\n","datagen = ImageDataGenerator(\n","        preprocessing_function=random_cutout(v_l=0, v_h=1))\n","\n","datagen.fit(x_train)\n","\n","#Mixup Augmentation\n","training_generator = MixupAugmentation(x_train, y_train, batch_size=batch_size, alpha=0.4, datagen = datagen)()\n","\n","plot = model.fit_generator(generator=training_generator,\n","                        steps_per_epoch=x_train.shape[0] // batch_size,\n","                        validation_data=(x_test, y_test),\n","                        epochs=epochs, verbose=1\n","                        )\n","             \n","\n","# Score trained model.\n","scores = model.evaluate(x_test, y_test, verbose=1)\n","print('Test loss:', scores[0])\n","print('Test accuracy:', scores[1])"],"execution_count":66,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","78/78 [==============================] - 27s 350ms/step - loss: 2.3851 - accuracy: 0.3152 - val_loss: 2.8039 - val_accuracy: 0.2050\n","Epoch 2/100\n","78/78 [==============================] - 21s 272ms/step - loss: 2.1354 - accuracy: 0.4265 - val_loss: 4.2242 - val_accuracy: 0.1299\n","Epoch 3/100\n","78/78 [==============================] - 21s 272ms/step - loss: 2.0060 - accuracy: 0.4857 - val_loss: 2.3513 - val_accuracy: 0.3396\n","Epoch 4/100\n","78/78 [==============================] - 21s 273ms/step - loss: 1.9292 - accuracy: 0.5142 - val_loss: 2.8936 - val_accuracy: 0.2117\n","Epoch 5/100\n","78/78 [==============================] - 21s 272ms/step - loss: 1.8387 - accuracy: 0.5373 - val_loss: 2.0545 - val_accuracy: 0.4038\n","Epoch 6/100\n","78/78 [==============================] - 21s 273ms/step - loss: 1.7698 - accuracy: 0.5752 - val_loss: 1.7944 - val_accuracy: 0.4821\n","Epoch 7/100\n","78/78 [==============================] - 21s 272ms/step - loss: 1.6933 - accuracy: 0.6076 - val_loss: 1.7335 - val_accuracy: 0.5025\n","Epoch 8/100\n","78/78 [==============================] - 21s 270ms/step - loss: 1.6673 - accuracy: 0.6216 - val_loss: 2.0335 - val_accuracy: 0.4247\n","Epoch 9/100\n","78/78 [==============================] - 21s 271ms/step - loss: 1.6278 - accuracy: 0.6417 - val_loss: 2.0733 - val_accuracy: 0.3762\n","Epoch 10/100\n","78/78 [==============================] - 21s 271ms/step - loss: 1.5637 - accuracy: 0.6698 - val_loss: 2.0108 - val_accuracy: 0.3733\n","Epoch 11/100\n","78/78 [==============================] - 21s 272ms/step - loss: 1.5311 - accuracy: 0.6830 - val_loss: 1.8387 - val_accuracy: 0.4922\n","Epoch 12/100\n","78/78 [==============================] - 21s 271ms/step - loss: 1.4732 - accuracy: 0.7184 - val_loss: 1.6948 - val_accuracy: 0.5084\n","Epoch 13/100\n","78/78 [==============================] - 21s 271ms/step - loss: 1.4538 - accuracy: 0.7181 - val_loss: 1.7409 - val_accuracy: 0.5381\n","Epoch 14/100\n","78/78 [==============================] - 21s 272ms/step - loss: 1.4169 - accuracy: 0.7393 - val_loss: 1.7835 - val_accuracy: 0.5071\n","Epoch 15/100\n","78/78 [==============================] - 21s 272ms/step - loss: 1.3896 - accuracy: 0.7477 - val_loss: 1.9271 - val_accuracy: 0.4674\n","Epoch 16/100\n","78/78 [==============================] - 21s 270ms/step - loss: 1.3615 - accuracy: 0.7643 - val_loss: 1.6081 - val_accuracy: 0.5459\n","Epoch 17/100\n","78/78 [==============================] - 21s 272ms/step - loss: 1.3429 - accuracy: 0.7754 - val_loss: 2.1792 - val_accuracy: 0.4524\n","Epoch 18/100\n","78/78 [==============================] - 21s 271ms/step - loss: 1.3094 - accuracy: 0.7894 - val_loss: 1.5971 - val_accuracy: 0.5757\n","Epoch 19/100\n","78/78 [==============================] - 21s 272ms/step - loss: 1.2909 - accuracy: 0.7972 - val_loss: 1.9237 - val_accuracy: 0.4774\n","Epoch 20/100\n","78/78 [==============================] - 21s 271ms/step - loss: 1.2587 - accuracy: 0.8064 - val_loss: 1.8117 - val_accuracy: 0.5068\n","Epoch 21/100\n","78/78 [==============================] - 21s 271ms/step - loss: 1.2659 - accuracy: 0.8047 - val_loss: 1.9749 - val_accuracy: 0.5111\n","Epoch 22/100\n","78/78 [==============================] - 21s 271ms/step - loss: 1.2419 - accuracy: 0.8138 - val_loss: 1.6982 - val_accuracy: 0.5354\n","Epoch 23/100\n","78/78 [==============================] - 21s 271ms/step - loss: 1.2159 - accuracy: 0.8218 - val_loss: 3.4522 - val_accuracy: 0.3292\n","Epoch 24/100\n","78/78 [==============================] - 21s 270ms/step - loss: 1.2194 - accuracy: 0.8203 - val_loss: 1.9409 - val_accuracy: 0.5098\n","Epoch 25/100\n","78/78 [==============================] - 21s 271ms/step - loss: 1.2085 - accuracy: 0.8268 - val_loss: 2.0815 - val_accuracy: 0.5050\n","Epoch 26/100\n","78/78 [==============================] - 21s 271ms/step - loss: 1.1991 - accuracy: 0.8348 - val_loss: 1.7544 - val_accuracy: 0.5407\n","Epoch 27/100\n","78/78 [==============================] - 21s 271ms/step - loss: 1.1785 - accuracy: 0.8358 - val_loss: 1.5418 - val_accuracy: 0.5739\n","Epoch 28/100\n","78/78 [==============================] - 21s 271ms/step - loss: 1.1709 - accuracy: 0.8457 - val_loss: 1.5752 - val_accuracy: 0.5728\n","Epoch 29/100\n","78/78 [==============================] - 21s 271ms/step - loss: 1.1807 - accuracy: 0.8366 - val_loss: 2.0764 - val_accuracy: 0.5130\n","Epoch 30/100\n","78/78 [==============================] - 21s 272ms/step - loss: 1.1663 - accuracy: 0.8443 - val_loss: 2.1469 - val_accuracy: 0.4890\n","Epoch 31/100\n","78/78 [==============================] - 21s 271ms/step - loss: 1.1551 - accuracy: 0.8434 - val_loss: 1.7694 - val_accuracy: 0.5151\n","Epoch 32/100\n","78/78 [==============================] - 21s 270ms/step - loss: 1.1541 - accuracy: 0.8491 - val_loss: 2.3431 - val_accuracy: 0.4498\n","Epoch 33/100\n","78/78 [==============================] - 21s 270ms/step - loss: 1.1431 - accuracy: 0.8560 - val_loss: 1.9298 - val_accuracy: 0.5021\n","Epoch 34/100\n","78/78 [==============================] - 21s 271ms/step - loss: 1.1412 - accuracy: 0.8531 - val_loss: 1.7365 - val_accuracy: 0.5478\n","Epoch 35/100\n","78/78 [==============================] - 21s 271ms/step - loss: 1.1293 - accuracy: 0.8588 - val_loss: 1.6405 - val_accuracy: 0.5626\n","Epoch 36/100\n","78/78 [==============================] - 21s 270ms/step - loss: 1.1180 - accuracy: 0.8630 - val_loss: 1.7229 - val_accuracy: 0.5484\n","Epoch 37/100\n","78/78 [==============================] - 21s 271ms/step - loss: 1.1226 - accuracy: 0.8610 - val_loss: 1.9381 - val_accuracy: 0.5358\n","Epoch 38/100\n","78/78 [==============================] - 21s 270ms/step - loss: 1.1082 - accuracy: 0.8640 - val_loss: 1.8937 - val_accuracy: 0.5111\n","Epoch 39/100\n","78/78 [==============================] - 21s 272ms/step - loss: 1.1246 - accuracy: 0.8593 - val_loss: 1.7929 - val_accuracy: 0.5124\n","Epoch 40/100\n","78/78 [==============================] - 21s 270ms/step - loss: 1.1158 - accuracy: 0.8572 - val_loss: 2.4194 - val_accuracy: 0.4781\n","Epoch 41/100\n","78/78 [==============================] - 21s 271ms/step - loss: 1.1023 - accuracy: 0.8665 - val_loss: 1.7002 - val_accuracy: 0.5504\n","Epoch 42/100\n","78/78 [==============================] - 21s 271ms/step - loss: 1.1011 - accuracy: 0.8671 - val_loss: 1.8353 - val_accuracy: 0.5164\n","Epoch 43/100\n","78/78 [==============================] - 21s 271ms/step - loss: 1.0881 - accuracy: 0.8689 - val_loss: 2.4205 - val_accuracy: 0.4143\n","Epoch 44/100\n","78/78 [==============================] - 21s 271ms/step - loss: 1.1125 - accuracy: 0.8567 - val_loss: 1.8288 - val_accuracy: 0.5205\n","Epoch 45/100\n","78/78 [==============================] - 21s 270ms/step - loss: 1.1027 - accuracy: 0.8642 - val_loss: 1.9119 - val_accuracy: 0.5052\n","Epoch 46/100\n","78/78 [==============================] - 21s 271ms/step - loss: 1.0877 - accuracy: 0.8701 - val_loss: 1.7055 - val_accuracy: 0.5320\n","Epoch 47/100\n","78/78 [==============================] - 21s 270ms/step - loss: 1.0805 - accuracy: 0.8738 - val_loss: 1.8217 - val_accuracy: 0.5467\n","Epoch 48/100\n","78/78 [==============================] - 21s 270ms/step - loss: 1.0978 - accuracy: 0.8634 - val_loss: 2.1598 - val_accuracy: 0.4495\n","Epoch 49/100\n","78/78 [==============================] - 21s 270ms/step - loss: 1.0762 - accuracy: 0.8742 - val_loss: 1.7637 - val_accuracy: 0.5397\n","Epoch 50/100\n","78/78 [==============================] - 21s 271ms/step - loss: 1.0797 - accuracy: 0.8715 - val_loss: 1.5913 - val_accuracy: 0.5843\n","Epoch 51/100\n","78/78 [==============================] - 21s 271ms/step - loss: 1.0751 - accuracy: 0.8757 - val_loss: 2.1615 - val_accuracy: 0.4752\n","Epoch 52/100\n","78/78 [==============================] - 21s 271ms/step - loss: 1.0768 - accuracy: 0.8741 - val_loss: 1.7370 - val_accuracy: 0.5198\n","Epoch 53/100\n","78/78 [==============================] - 21s 270ms/step - loss: 1.0587 - accuracy: 0.8804 - val_loss: 1.9365 - val_accuracy: 0.4938\n","Epoch 54/100\n","78/78 [==============================] - 21s 271ms/step - loss: 1.0657 - accuracy: 0.8796 - val_loss: 1.9840 - val_accuracy: 0.5208\n","Epoch 55/100\n","78/78 [==============================] - 21s 270ms/step - loss: 1.0585 - accuracy: 0.8764 - val_loss: 1.8413 - val_accuracy: 0.5013\n","Epoch 56/100\n","78/78 [==============================] - 21s 271ms/step - loss: 1.0672 - accuracy: 0.8804 - val_loss: 1.8992 - val_accuracy: 0.5031\n","Epoch 57/100\n","78/78 [==============================] - 21s 271ms/step - loss: 1.0661 - accuracy: 0.8760 - val_loss: 1.5034 - val_accuracy: 0.5833\n","Epoch 58/100\n","78/78 [==============================] - 21s 271ms/step - loss: 1.0568 - accuracy: 0.8870 - val_loss: 1.9475 - val_accuracy: 0.4890\n","Epoch 59/100\n","78/78 [==============================] - 21s 270ms/step - loss: 1.0630 - accuracy: 0.8774 - val_loss: 2.0085 - val_accuracy: 0.4829\n","Epoch 60/100\n","78/78 [==============================] - 21s 271ms/step - loss: 1.0395 - accuracy: 0.8801 - val_loss: 1.6987 - val_accuracy: 0.5191\n","Epoch 61/100\n","78/78 [==============================] - 21s 270ms/step - loss: 1.0596 - accuracy: 0.8801 - val_loss: 1.9522 - val_accuracy: 0.4907\n","Epoch 62/100\n","78/78 [==============================] - 21s 270ms/step - loss: 1.0666 - accuracy: 0.8773 - val_loss: 2.1835 - val_accuracy: 0.4524\n","Epoch 63/100\n","78/78 [==============================] - 21s 271ms/step - loss: 1.0499 - accuracy: 0.8823 - val_loss: 1.9259 - val_accuracy: 0.4628\n","Epoch 64/100\n","78/78 [==============================] - 21s 270ms/step - loss: 1.0279 - accuracy: 0.8833 - val_loss: 1.5593 - val_accuracy: 0.5664\n","Epoch 65/100\n","78/78 [==============================] - 21s 270ms/step - loss: 1.0456 - accuracy: 0.8832 - val_loss: 1.7095 - val_accuracy: 0.5395\n","Epoch 66/100\n","78/78 [==============================] - 21s 270ms/step - loss: 1.0362 - accuracy: 0.8819 - val_loss: 1.5434 - val_accuracy: 0.5699\n","Epoch 67/100\n","78/78 [==============================] - 21s 270ms/step - loss: 1.0356 - accuracy: 0.8829 - val_loss: 2.1098 - val_accuracy: 0.4479\n","Epoch 68/100\n","78/78 [==============================] - 21s 271ms/step - loss: 1.0350 - accuracy: 0.8803 - val_loss: 1.6209 - val_accuracy: 0.5445\n","Epoch 69/100\n","78/78 [==============================] - 21s 271ms/step - loss: 1.0332 - accuracy: 0.8867 - val_loss: 1.6316 - val_accuracy: 0.5583\n","Epoch 70/100\n","78/78 [==============================] - 21s 271ms/step - loss: 1.0300 - accuracy: 0.8865 - val_loss: 1.6802 - val_accuracy: 0.5544\n","Epoch 71/100\n","78/78 [==============================] - 21s 271ms/step - loss: 1.0378 - accuracy: 0.8847 - val_loss: 1.6376 - val_accuracy: 0.5605\n","Epoch 72/100\n","78/78 [==============================] - 21s 271ms/step - loss: 1.0174 - accuracy: 0.8894 - val_loss: 1.9769 - val_accuracy: 0.4967\n","Epoch 73/100\n","78/78 [==============================] - 21s 271ms/step - loss: 1.0273 - accuracy: 0.8870 - val_loss: 1.7817 - val_accuracy: 0.5318\n","Epoch 74/100\n","78/78 [==============================] - 21s 272ms/step - loss: 1.0269 - accuracy: 0.8817 - val_loss: 1.8944 - val_accuracy: 0.4952\n","Epoch 75/100\n","78/78 [==============================] - 21s 273ms/step - loss: 1.0154 - accuracy: 0.8928 - val_loss: 1.5934 - val_accuracy: 0.5699\n","Epoch 76/100\n","78/78 [==============================] - 21s 272ms/step - loss: 1.0200 - accuracy: 0.8832 - val_loss: 1.6600 - val_accuracy: 0.5457\n","Epoch 77/100\n","78/78 [==============================] - 21s 274ms/step - loss: 1.0127 - accuracy: 0.8857 - val_loss: 1.5623 - val_accuracy: 0.5761\n","Epoch 78/100\n","78/78 [==============================] - 21s 271ms/step - loss: 1.0194 - accuracy: 0.8882 - val_loss: 1.6038 - val_accuracy: 0.5538\n","Epoch 79/100\n","78/78 [==============================] - 21s 272ms/step - loss: 1.0127 - accuracy: 0.8914 - val_loss: 1.7557 - val_accuracy: 0.5382\n","Epoch 80/100\n","78/78 [==============================] - 21s 273ms/step - loss: 1.0109 - accuracy: 0.8887 - val_loss: 1.6843 - val_accuracy: 0.5537\n","Epoch 81/100\n","78/78 [==============================] - 21s 274ms/step - loss: 1.0164 - accuracy: 0.8864 - val_loss: 2.7608 - val_accuracy: 0.3565\n","Epoch 82/100\n","78/78 [==============================] - 21s 272ms/step - loss: 0.9949 - accuracy: 0.8931 - val_loss: 1.4436 - val_accuracy: 0.6101\n","Epoch 83/100\n","78/78 [==============================] - 21s 273ms/step - loss: 1.0011 - accuracy: 0.8968 - val_loss: 1.7656 - val_accuracy: 0.5047\n","Epoch 84/100\n","78/78 [==============================] - 21s 274ms/step - loss: 1.0143 - accuracy: 0.8864 - val_loss: 1.6744 - val_accuracy: 0.5378\n","Epoch 85/100\n","78/78 [==============================] - 21s 272ms/step - loss: 1.0125 - accuracy: 0.8878 - val_loss: 1.5653 - val_accuracy: 0.5787\n","Epoch 86/100\n","78/78 [==============================] - 21s 272ms/step - loss: 1.0036 - accuracy: 0.8936 - val_loss: 1.6266 - val_accuracy: 0.5424\n","Epoch 87/100\n","78/78 [==============================] - 21s 272ms/step - loss: 0.9956 - accuracy: 0.8983 - val_loss: 1.7423 - val_accuracy: 0.5445\n","Epoch 88/100\n","78/78 [==============================] - 21s 272ms/step - loss: 0.9942 - accuracy: 0.8949 - val_loss: 1.6332 - val_accuracy: 0.5617\n","Epoch 89/100\n","78/78 [==============================] - 21s 272ms/step - loss: 1.0071 - accuracy: 0.8858 - val_loss: 1.8633 - val_accuracy: 0.5352\n","Epoch 90/100\n","78/78 [==============================] - 21s 271ms/step - loss: 1.0009 - accuracy: 0.8904 - val_loss: 1.8162 - val_accuracy: 0.5446\n","Epoch 91/100\n","78/78 [==============================] - 21s 270ms/step - loss: 0.9992 - accuracy: 0.8937 - val_loss: 1.8817 - val_accuracy: 0.4941\n","Epoch 92/100\n","78/78 [==============================] - 21s 270ms/step - loss: 0.9829 - accuracy: 0.8998 - val_loss: 1.5811 - val_accuracy: 0.5542\n","Epoch 93/100\n","78/78 [==============================] - 21s 272ms/step - loss: 0.9893 - accuracy: 0.8949 - val_loss: 1.8885 - val_accuracy: 0.4793\n","Epoch 94/100\n","78/78 [==============================] - 21s 271ms/step - loss: 0.9896 - accuracy: 0.8990 - val_loss: 1.8722 - val_accuracy: 0.5215\n","Epoch 95/100\n","78/78 [==============================] - 21s 270ms/step - loss: 0.9955 - accuracy: 0.8898 - val_loss: 1.9540 - val_accuracy: 0.4690\n","Epoch 96/100\n","78/78 [==============================] - 21s 270ms/step - loss: 0.9910 - accuracy: 0.8918 - val_loss: 1.4015 - val_accuracy: 0.6145\n","Epoch 97/100\n","78/78 [==============================] - 21s 271ms/step - loss: 0.9821 - accuracy: 0.8953 - val_loss: 1.8411 - val_accuracy: 0.4960\n","Epoch 98/100\n","78/78 [==============================] - 21s 270ms/step - loss: 0.9847 - accuracy: 0.8962 - val_loss: 1.5689 - val_accuracy: 0.5724\n","Epoch 99/100\n","78/78 [==============================] - 21s 270ms/step - loss: 0.9828 - accuracy: 0.8959 - val_loss: 1.7554 - val_accuracy: 0.5153\n","Epoch 100/100\n","78/78 [==============================] - 21s 270ms/step - loss: 0.9856 - accuracy: 0.8941 - val_loss: 1.4960 - val_accuracy: 0.5746\n","10000/10000 [==============================] - 8s 789us/step\n","Test loss: 1.4960438161849976\n","Test accuracy: 0.5745999813079834\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Sw6tKj_JGme7","colab_type":"text"},"source":["Plot : Accuracy"]},{"cell_type":"code","metadata":{"id":"MmsUfZrE-U3G","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","\n","plt.figure(0)\n","plt.plot(plot.history['accuracy'], label='Training Accuracy')\n","plt.plot(plot.history['val_accuracy'], label='Test Accuracy')\n","plt.title('Accuracy')\n","plt.xlabel('epochs')\n","plt.ylabel('accuracy')\n","plt.legend()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5C77xUzwGpLV","colab_type":"text"},"source":["Plot : Loss"]},{"cell_type":"code","metadata":{"id":"X3uBxLjm-96q","colab_type":"code","colab":{}},"source":["plt.plot(plot.history['loss'], label='Training Loss')\n","plt.title('Loss')\n","plt.xlabel('epochs')\n","plt.ylabel('loss')\n","plt.legend()"],"execution_count":0,"outputs":[]}]}